

\documentclass[12pt]{article}
\usepackage{authblk}
\usepackage{setspace}
\usepackage[utf8]{inputenc}
\usepackage[margin=1.25in]{geometry}
\usepackage{graphicx}
\graphicspath{ {./figures/} }
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{lineno}
\usepackage{fontspec}
% \linenumbers

%%%%%% Bibliography %%%%%%
% Replace "sample" in the \addbibresource line below with the name of your .bib file.
\usepackage[style=ieee, citestyle=numeric-comp,sorting=none]{biblatex}
\addbibresource{bib.bib}

%%%%%% Title %%%%%%
% Full titles can be a maximum of 200 characters, including spaces. 
% Title Format: Use title case, capitalizing the first letter of each word, except for certain small words, such as articles and short prepositions
\title{Military AI Deployment through the Lens of \break  Ethical Theories}

%%%%%% Authors %%%%%%
% Authors should be listed in order of contribution to the paper, by first name, then middle initial (if any), followed by last name.
% Authors should be listed in the order in which they will appear in the published version if the manuscript is accepted. 
% Use an asterisk (*) to identify the corresponding author, and be sure to include that person’s e-mail address. Use symbols (in this order: †, ‡, §, ||, ¶, #, ††, ‡‡, etc.) for author notes, such as present addresses, “These authors contributed equally to this work” notations, and similar information.
% You can include group authors, but please include a list of the actual authors (the group members) in the Supplementary Materials.
\author[1,*]{21125060 - Nguyen Minh Quang}
\author[2,*]{21125155 - Diep Tuong Nghiem}
% \author[2]{Author Three}
% \author[1,2]{Author Four}

%%%%%% Affiliations %%%%%%
\affil[*]{VNUHCM - University of Science}
\affil[1]{nmquang21@apcs.fitus.edu.vn}
\affil[2]{dtnghiem21@apcs.fitus.edu.vn}
% \affil[$\dag$]{These authors contributed equally to this work.}

%%%%%% Date %%%%%%
% Date is optional
\date{}

%%%%%% Spacing %%%%%%
% Use paragraph spacing of 1.5 or 2 (for double spacing, use command \doublespacing)
\singlespacing
\setmainfont{Times New Roman}
\begin{document}

\maketitle

\begin{abstract}
As the pages of 2022 and 2023 turned, the world witnessed wars between countries. With the high-tech devices and the prosperous development of Artificial Intelligence, many countries are integrating AI algorithms into their military systems. This can be an innovative step for a country to enhance its nation's protection. However, the actions of abusing and exploiting this technology in the realm of warfare are inevitable. As battles evolve, damage to humans drops off while weapon accessibility skyrockets. This shift empowers individuals to wield automated arsenals capable of massive destruction. In this paper, we will analyze the ethical implications of AI's development in the military with three ethical theories, and these analyses conclude that depending on the way and purpose of applying AI to the military, it becomes moral or not.
\end{abstract}

\section{Introduction}
The military is an organization that works for a country to protect national security and maintain sovereignty. It is expected to handle threats and conflicts from the internal and external of a nation. The roles of the military can be extended beyond combat and defense. The forces can be used to rescue people from natural disasters or to transport food and medicine.

According to the Cambridge Dictionary, war is \textit{"armed fighting between two or more countries or groups"} \cite{war-def-cambridge}. The groups can be countries, states, or insurgents. War is usually involves with violence, weapons, morality, and humanity. When the Second World War slowly faded, modern warfare unfolded not only on traditional battlefields but also in the vast expanse of cyberspace.

Wars are a constant in human history and still exist between countries in the twenty-first century. In the twenty-first century, humans have witnessed many wars worldwide, and they continue. Since 2011, a war named the Syrian Civil War has caused the deaths of hundreds of thousands of people and displaced millions more. In Ethiopia, the Tigray War is a civil war that has been going on since November 2020, and thousands of people have been killed. Therefore, this conflict has also led to a humanitarian crisis, and millions need food, water, and shelter. In February 2022, the conflict between Russia and Ukraine escalated, leading to the invasion of Russia into Ukraine. Due to the peril of war, countries are driven to enhance their military capabilities significantly.

Lethal Autonomous Weapons Systems (LAWS) refer to weaponry systems capable of autonomously identifying and engaging targets without human intervention. The nations at the forefront of the development of LAWS are the United States, Russia, and China. These systems' development and future remain subjects of ongoing deliberation because they are related to morality and have many ethical implications.

\textit{ Artificial intelligence, or AI, is increasingly touching people’s lives in settings that range from movie recommendations and voice assistants to autonomous driving and automated medical diagnoses} \cite{unknown-author-2021}. AI has been a powerful tool for humans to do jobs. In 2020, OpenAI's GPT-3 language model was introduced. It can generate coherent and contextually relevant text across a wide range of topics. Therefore, companies can use this to create chatboxes answering the customers. Midjourney is an art-generated AI that can help users generate artwork by telling their imagination. Hence, AI creates significant impacts on daily life.


Due to the rapidly developing versatility of AI, it can potentially revolutionize the military. Many automated robots can independently do surveillance, navigation, and transferring tasks. Therefore, military operations are improved in several ways, such as making better decisions, increasing efficiency, and reducing risk.

Project Maven is a Pentagon program that aims to speed up the use of artificial intelligence across the military. It was once the Pentagon's top-priority program but is now being transferred to the National Geospatial-Intelligence Agency (NGA) \cite{hitchens-2022}. The transfer will bring two major Defense Department AI/ML projects "together under one roof." The NGA already has an ongoing effort to leverage artificial intelligence (AI) and apply machine learning (ML) algorithms "to enable joint analysis at scale." The agency has been cooperating with the Pentagon since Maven was stood up in 2017 \cite{hitchens-2022}.


\section{Ethical concerns}
Besides the potential advantages of AI in the military, there are still many ethical concerns when using AI in the military. Because of this integration, there are many concerns raised about the potential of autonomous weapons, weapons that can select multi-target without human intervention. From that, applying AI to the military allows a person to have the ability to activate many massive destructive weapons through a singular interface.  

With the current technologies from companies, many products used for daily activities and making life more accessible can be weaponized. Drones are flying machines that can be utilized for many purposes. It can be used for live streaming an event, recording some wonderful, spectacular moments with family and friends. With all the abilities a drone can have, many military organizations offer autonomous drones with AI programs. Neurala \cite{neurala-no-date} offers an AI software called Neurala Brain that could allow military drones to conduct surveillance and patrol missions, or Lockheed Martin \cite{lockheedmartin} offers Desert Hawk III, a drone that can purportedly train operators on how to use it in the field \cite{roth-2019}.

In Russia, AI technology has been integrated into various weapons, exemplified by the T-14 tank. Nick de Larrinaga, the European editor at IHS Jane’s Defence Weekly, notes that the T-14 marks Russia's first substantial tank innovation since the 1970s \cite{williams-2018}. The tank showcases automated functions like environment scanning for enemy detection and target recognition. Although there's limited information presently, Russian claims suggest the potential for a fully unmanned tank version in the future.

There are many concerns about the loss of human control over the use of force. With the development of AI in the military, many countries intend to permit AI to attack many targets automatically. However, this permission has a significant risk; any failure of the AI system that causes the weapon to engage the inappropriate target could lead to potentially catastrophic problems such as civilian casualties or unintended escalation in a crisis \cite{autoweapon}. 

The algorithm for computer vision, capable of object recognition, including armed weapons, introduces a potential apprehension. Specifically, there is a concern that the algorithm's capability to differentiate between a child and an adult and discern between real and toy weapons might prove inadequate \cite{nationaldefense}. This could result in the algorithm inaccurately identifying a child or a shorter individual as a potential threat and similarly misinterpreting a harmless toy weapon as an actual armor. Although machines can flawlessly obey predefined laws, an ethical dilemma emerges concerning their capacity to make morally nuanced decisions.

\section{Background of Ethical Theories}
\subsection{Kantianism}
Kantianism is an ethical theory that was proposed by the German philosopher Immanuel Kant (1724–1804). Kant believed that people’s actions ought to be guided by moral laws and that these laws were universal. In order to apply to all rational beings, any supreme principle of morality must itself be based on reason. Kant concluded that the only thing in the world that can be called good without qualification is goodwill \cite{slideethic}. 

For Kant, an imperative is a way that makes reason command the will. There are two kinds of imperative: hypothesis imperative and categorical imperative. A hypothesis imperative is a conditional imperative that tells that you should do something to achieve a particular end. It has the form \textit{"If you want to obtain X, do Y"}. The categorical imperative is an unconditional imperative that can be applied to any situation \cite{quinn-2017}.

Following Kant, only a categorical imperative can be a moral imperative. There are two forms of categorical imperative. The first formulation is \textit{"Act only from moral rules that you can at the same time will be
universal moral laws"}. The second formulation is "Act so that you always treat both yourself and other people as ends in themselves, and never only as a means to an end" \cite{quinn-2017}.

\subsection{Utilitarianism}
Utilitarianism is one of the workable ethical theories people can use to evaluate moral problems \cite{quinn-2017}. It is an ethical theory that supports the actions of maximizing the benefits. 
    
With Utilitarianism, a person must consider the pros and cons of an action carefully. The consequences of the movement must be normalized into the same unit. By this, that person can apply subtraction and addition to estimate the total amount of benefits. However, it is only sometimes about maximizing the benefits in real life. It is worth considering that estimating pros and cons is sometimes highly complicated. Trying to put more effort into looking for more factors may have negative impacts due to wasting time.

The weakness of this theory can be mitigated by introducing the Rule utilitarianism. This theory will take the moral rules as a factor for the decisions. Thus, this theory will be supported by Kantanism theory. Therefore, the moral rules will be maintained in the available options.

\subsection{Social Contract}
Based on the formal definition of social contract theory given by James Rachels, Morality consists of the set of rules governing how people are to treat one another that rational people will agree to accept for their mutual
benefit, on the condition that others follow those rules as well \cite{rachels-1986}. 

There exists a close connection between rights and duties, where rights can be categorized according to the responsibilities they impose on others. Rights can be classified as negative rights and positive rights. 

A negative right provides us permission to do things that are not restricted by law. Therefore, nobody can interfere with other people to obtain their own rights. There are many negative rights, such as Freedom of religion, Freedom of speech, Natural right to self-ownership.

A positive right can guarantee service from other people. They are things that someone must provide to us, whether we have earned them or not. Public education, Health care, and Social security are examples of positive rights.

\section{Application of Ethical Theories}
\subsection{Kantianism}
One of the most critical categories of Kantianism is the principle of non-maleficence, which states that we should never do harm to others. This principle would seem to prohibit the use of AI in the military, as it could lead to damage to civilians. For example, in the Maven project, the U.S. has the intention to deploy an AI system into the military with the purpose of identifying targets more accurately and attacking them. They have tried this system in Iraq and Syria to identify insurgent targets in Syria and Iraq \cite{AIinNS}. 

In the military sphere, the support for autonomous weaponry often stems from logical goals. This involves justifying the intentional cessation of specific lives and the acceptance of sacrifices to protect a more extensive population's well-being. However, according to Kant, eliminating some people with lesser value to prevent further harm from other people is not sufficient to conclude that it is moral, which overrides human dignity and may be reckless if alternatives and consequences are not considered \cite{KaninAI}.

Nevertheless, in certain circumstances, using AI in the military could be justified following Kantianism if this behavior is just for good, not for harm. Some countries apply AI to the military to protect their civilians more efficiently against other countries or big catastrophes. These points make the use of AI in the military could be justified following Kantianism.  

\subsection{Utilitarianism}
Utilitarians argue that the use of AI in the military can lead to a net increase in human welfare because they believe that the potential benefits, such as reduced casualties, more efficient operations, and improved strategic decision-making, might outweigh the negative consequences, ultimately resulting in greater overall well-being for society.

AI can also help win a war quickly and decisively, even if it leads to civilian casualties. Since the fight can be rapidly stopped, the conflicts, pain, and difficulties end in a short amount of time. Using nuclear weapons by the U.S. prevented the U.S. from having to invade Japan, which would have resulted in even more casualties. Moreover, it brought about a quick end to the war, saving lives in the long run.

Moreover, the military is not always about wars. \textit{"AI has provided rescue crews access to disaster-stricken zones without any risks of injury or fatigue."} \cite{Sud2020}. Since AI can be deployed in disaster-stricken areas to provide relief and assistance during natural disasters like earthquakes, hurricanes, and floods, the military can use this power to identify situations, recognize people, and rescue them efficiently.

It can be observed that there is a likelihood of errors emerging when AI takes control of the weapons and makes decisions without human intervention. In such occurrences, it is difficult to identify the responsible subject for the course of action.

\subsection{Social Contract}
Following the Social Contract, it would argue that using AI in the military could be justified if used to protect citizens from harm. From that view, it provides civilians with the right to safety. An example of this view is that some countries use AI systems to deter aggression or prevent a war. Moreover, they have utilized it to safeguard the citizens from natural catastrophes by swiftly and accurately identifying these impending disasters.

In contrast, social contract theorists would also argue that using AI in the military must be subject to strict controls. AI systems must be designed to minimize civilian casualties because of the right to life and the right to Human Oversight. They must be subject to human oversight and should respect the autonomy of civilians not involved in the conflict. In April 2021, the European Union proposed a legal framework for AI that includes strict requirements for high-risk AI systems, such as those used in critical infrastructure, education, and employment \cite{unknown-author-2023}.

It seems that appropriate attention must be directed toward the training datasets. While high-precision algorithms require substantial volumes of clean data for effective learning, such data originates from the general populace. This can violate the right to privacy. Consequently, the enforcement of stringent regulations becomes essential.


\section{Future Considerations}
In the future, AI become more powerful, sophisticated, and affordable.
Numerous leaders have foreseen the trajectory of global development. \textit{“Artificial intelligence is the future, not only for Russia but for all humankind. It comes with colossal opportunities but also threats that are difficult to predict. Whoever becomes the leader in this sphere will become the world's ruler”} Russian President Vladimir Putin said \cite{rt-2017}. Nations will allocate their resources towards advancing autonomous machines, especially AI. 

The use of AI in the military is likely to become widespread among countries, and the efficiency and accuracy of automated weapons will also be improved significantly. Because of that, the ethical implications of AI use in the military need to be carefully considered to ensure that it is used for good and not for harm. Therefore, humans need to develop comprehensive international norms and regulations governing the use of AI in the army.

\section{Conclusion}
The use of AI in the military is a complex issue with several ethical implications. It can strengthen the military capabilities in combat, defense, and logistics but can create vast destruction in conflicts. Therefore, using AI may be counterproductive and promote the collapse of human civilization.

As the integration of AI into military applications becomes more widespread on a global scale, an escalating demand arises for international agreements or frameworks that establish ethical guidelines for its use. These agreements would address concerns related to the human rights violations that might occur from the deployment of AI in military operations. Such contracts are crucial for maintaining stability and upholding the principles of justice and rights internationally.

It is essential to carefully consider these implications before deploying AI systems in warfare to ensure that this technology's utilization remains aligned with virtuous ends. Technology companies must create software to prevent AI abuse, and AI systems must be designed to encourage righteous behavior. Rigorous laws must be enacted to protect morality and human rights.

\printbibliography

\end{document}
