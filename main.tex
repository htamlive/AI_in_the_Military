

\documentclass{article}
\usepackage{authblk}
\usepackage{setspace}
\usepackage[utf8]{inputenc}
\usepackage[margin=1.25in]{geometry}
\usepackage{graphicx}
\graphicspath{ {./figures/} }
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{lineno}
% \linenumbers

%%%%%% Bibliography %%%%%%
% Replace "sample" in the \addbibresource line below with the name of your .bib file.
\usepackage[style=ieee, citestyle=numeric-comp,sorting=none]{biblatex}
\addbibresource{bib.bib}

%%%%%% Title %%%%%%
% Full titles can be a maximum of 200 characters, including spaces. 
% Title Format: Use title case, capitalizing the first letter of each word, except for certain small words, such as articles and short prepositions
\title{Artificial Intelligence and Military}

%%%%%% Authors %%%%%%
% Authors should be listed in order of contribution to the paper, by first name, then middle initial (if any), followed by last name.
% Authors should be listed in the order in which they will appear in the published version if the manuscript is accepted. 
% Use an asterisk (*) to identify the corresponding author, and be sure to include that person’s e-mail address. Use symbols (in this order: †, ‡, §, ||, ¶, #, ††, ‡‡, etc.) for author notes, such as present addresses, “These authors contributed equally to this work” notations, and similar information.
% You can include group authors, but please include a list of the actual authors (the group members) in the Supplementary Materials.
\author[1,*]{21125060 - Nguyen Minh Quang}
\author[2,*]{21125155 - Diep Tuong Nghiem}
% \author[2]{Author Three}
% \author[1,2]{Author Four}

%%%%%% Affiliations %%%%%%
\affil[*]{VNUHCM - University of Science}
\affil[1]{nmquang21@apcs.fitus.edu.vn}
\affil[2]{dtnghiem21@apcs.fitus.edu.vn}
% \affil[$\dag$]{These authors contributed equally to this work.}

%%%%%% Date %%%%%%
% Date is optional
\date{}

%%%%%% Spacing %%%%%%
% Use paragraph spacing of 1.5 or 2 (for double spacing, use command \doublespacing)
\onehalfspacing

\begin{document}

\maketitle

\begin{abstract}
As the pages of 2022 and 2023 turned, the world witnessed wars between countries. With the high-tech devices and the prosperous development of Artificial Intelligence, many countries are integrating AI algorithms into their military systems. This can be an innovative step for a country to enhance its nation's protection. However, the actions of abusing and exploiting this technology in the realm of warfare are inevitable. As battles evolve, damage to humans drops off while weapon accessibility skyrockets. This shift empowers individuals to wield automated arsenals capable of massive destruction. In this paper, we will analyze the ethical implications of AI's development in warfare, and some solutions are recommended.
\end{abstract}

\section{Introduction}
The military is an organization that works for a country to protect national security and maintain sovereignty. It is expected to handle threats and conflicts from the internal and external of a nation. The roles of the military can be extended beyond combat and defense. The forces can be used to rescue people from natural disasters or to transport food and medicine.

According to the Cambridge Dictionary, war is \textit{armed fighting between two or more countries or groups} \cite{war-def-cambridge}. The groups can be countries, states, or insurgents. War is usually involves with violence, weapons, morality, and humanity. Since the Second World War slowly faded, modern warfare unfolded not only on traditional battlefields but also in the vast expanse of cyberspace.

Wars are a constant in human history and still exist between countries in the twenty-first century. Since 2011, humans have witnessed many wars worldwide, and they continue. Since 2011, a war named the Syrian Civil War has caused the deaths of hundreds of thousands of people and displaced millions more. In Ethiopia, the Tigray War is a civil war that has been going on since November 2020 and has killed thousands of people and displaced millions more. The conflict has also led to a humanitarian crisis, with millions needing food, water, and shelter. In February 2022, Russia invaded Ukraine. Due to the peril of war, countries are driven to enhance their military capabilities significantly.

Lethal Autonomous Weapons Systems (LAWS) encompass weaponry systems with the capacity to identify and engage targets devoid of human involvement autonomously. The nations at the forefront of the development of LAWS are the United States, Russia, and China. These systems' development and future remain subjects of ongoing deliberation because they are related to morality and have many ethical implications.

\textit{ Artificial intelligence, or AI, is increasingly touching people’s lives in settings that range from movie recommendations and voice assistants to autonomous driving and automated medical diagnoses.} \cite{unknown-author-2021}. AI has been a powerful tool for humans to do jobs. In 2020, OpenAI's GPT-3 language model was introduced. It can generate coherent and contextually relevant text across a wide range of topics. Therefore, companies can use this to create chatboxes answering the customers. Midjourney is an art-generated AI that can help users create artwork by telling their imagination. 

%% Thêm application ngày nay và dẫn chứng chỗ này

Due to the rapidly developing versatility of AI, it can potentially revolutionize the military. Many automated robots can independently do surveillance, navigation, and transferring tasks. Therefore, military operations are improved in several ways, such as making better decisions, increasing efficiency, and reducing risk.

Project Maven is a Pentagon program that aims to speed up the use of artificial intelligence across the military. It was once the Pentagon's top-priority program but is now being transferred to the National Geospatial-Intelligence Agency (NGA). The transfer will bring two major Defense Department AI/ML projects "together under one roof." The NGA already has an ongoing effort to leverage artificial intelligence (AI) and apply machine learning (ML) algorithms "to enable joint analysis at scale." The agency has been cooperating with the Pentagon since Maven was stood up in 2017. \cite{hitchens-2022}

%Một số applications of AI in the military

\section{Ethical concerns}
Besides the potential advantages of AI in the military, there are still many ethical concerns when using AI in the military. Because of this integration, there are many concerns raised about the potential of autonomous weapons, weapons that can select multi-target without human intervention. From that, applying AI to the military allows a person to have the ability to activate many massive destructive weapons with only one button.  

There are also some concerns about the loss of human control over the use of force. With the development of AI in the military, many countries intend to permit AI to attack many targets automatically. However, this permission has a significant risk; any failure of the AI system that causes the weapon to engage the inappropriate target could lead to potentially catastrophic problems such as civilian casualties or unintended escalation in a crisis \cite{autoweapon}.

\section{Ethical Theories}
\subsection{Kantianism}
One of the most critical categories of Kantianism is the principle of non-maleficence, which states that we should never do harm to others. This principle would seem to prohibit the use of AI in the military, as it could lead to damage to civilians. For example, in the Maven project, the U.S. has the intention to deploy an AI system into the military with the purpose of identifying targets more accurately and attacking them. They have tried this system in Iraq and Syria to identify insurgent targets in Syria and Iraq \cite{AIinNS}. 

In the military sphere, the use of autonomous weapons is often advocated for a reasonable purpose. It is often argued that killing some people and sacrificing their lives with the hope of protecting others. However, according to Kant, eliminating some people with lesser value to prevent further harm from other people is not sufficient to conclude that it is moral, which overrides human dignity and may be reckless if alternatives and consequences are not considered \cite{KaninAI}.

Nevertheless, in certain circumstances, the use of AI in the military could be justified following Kantianism if this behavior is just for good, not for harm. In some countries, they apply AI to the military with the purpose of protecting their civilians more efficiently against other countries or big catastrophes. These points make the use of AI in the military could be justified following Kantianism.  

\subsection{Utilitarianism}
Utilitarians argue that the use of AI in the military can lead to a net increase in human welfare because they believe that the potential benefits, such as reduced casualties, more efficient operations, and improved strategic decision-making, might outweigh the negative consequences, ultimately resulting in greater overall well-being for society.

AI can also help win a war quickly and decisively, even if it leads to civilian casualties. Since the fight can be rapidly stopped, the conflicts, pain, and difficulties end in a short amount of time. Using nuclear weapons by the U.S. prevented the U.S. from having to invade Japan, which would have resulted in even more casualties and brought about a quick end to the war, saving lives in the long run.

Moreover, the military is not always about wars. \textit{"AI has provided rescue crews access to disaster-stricken zones without any risks of injury or fatigue."} \cite{Sud2020}. Since AI can be deployed in disaster-stricken areas to provide relief and assistance during natural disasters like earthquakes, hurricanes, and floods, the military can use this power to identify situations, recognize people, and rescue them efficiently.

It can be observed that the result of

\subsection{Social Contract}

However, social contract theorists would also argue that using AI in the military must be subject to strict controls. AI systems must be designed to minimize civilian casualties because of the right to life and the right to Human Oversight. They must be subject to human oversight and should respect the autonomy of civilians not involved in the conflict. In April 2021, the European Union proposed a legal framework for AI that includes strict requirements for high-risk AI systems, such as those used in critical infrastructure, education, and employment \cite{unknown-author-2023}.

\section{Comparative Analysis and Synthesis}

\section{Future Considerations}
In the future, AI become more powerful, sophisticated, and affordable. “Artificial intelligence is the future, not only for Russia but for all humankind. It comes with colossal opportunities but also threats that are difficult to predict. Whoever becomes the leader in this sphere will become the world's ruler,” Russian President Vladimir Putin said \cite{rt-2017}. Nations will allocate their resources towards advancing autonomous machines, especially AI. 

The use of AI in the military is likely to become widespread among countries, and the efficiency and accuracy of automated weapons will be also improved significantly. Because of that, it is important to carefully consider the ethical implications of its use in the military to ensure that it is used for good and not for harm. Therefore, Humans need to develop comprehensive international norms and regulations governing the use of AI in warfare.

\section{Conclusion}
The use of AI in the military is a complex issue with several ethical implications. Therefore, it is essential to carefully consider these implications before deploying AI systems in warfare to ensure that this technology's utilization remains aligned with virtuous ends. Rigorous laws must be enacted to protect morality and human rights.


\cite{Kessel2019nytimes}, \cite{2020Military}

\printbibliography

% \section{References}

% Laker, B. (2023, May 9). AI At The Crossroads: Navigating Job Displacement, Ethical Concerns, And The Future Of Work. Forbes. https://www.forbes.com/sites/benjaminlaker/2023/05/09/ai-at-the-crossroads-navigating-job-displacement-ethical-concerns-and-the-future-of-work/

% Ethics and automation: What to do when workers are displaced | MIT Sloan. (2019, July 8). MIT Sloan. https://mitsloan.mit.edu/ideas-made-to-matter/ethics-and-automation-what-to-do-when-workers-are-displaced

% The Ethics of Artificial Intelligence in the Workplace: How to Balance Innovation with Responsibility. (n.d.). The Ethics of Artificial Intelligence in the Workplace: How to Balance Innovation With Responsibility. https://www.linkedin.com/pulse/ethics-artificial-intelligence-workplace-how-balance-igor-alcantara

% Kessel, Reneau, and Chan. (2019, December 12). nytimes - A.I. Is Making It Easier to Kill (You). Here’s How. [Video]. https://www.nytimes.com/. Retrieved August 10, 2023, from https://www.nytimes.com/video/technology/100000006082083/lethal-autonomous-weapons.html







\end{document}
